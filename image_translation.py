# -*- coding: utf-8 -*-
"""Image_Translation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ggCNp25AYJ80il31GJWTXkoGceq0YTQz
"""

# ‚úÖ Fix TensorFlow version to 2.11.0 (full version, not just CPU)
!pip uninstall -y tensorflow tensorflow-cpu
!pip install tensorflow==2.11.0

import tensorflow as tf
import matplotlib.pyplot as plt

# ‚öôÔ∏è Path for the map dataset
# Ensure the 'maps' dataset is downloaded and extracted to this location.
# The training images should be in '/content/pytorch-CycleGAN-and-pix2pix/datasets/maps/train/'
PATH = '/content/pytorch-CycleGAN-and-pix2pix/datasets/maps'

# ‚Äî Preprocessing ‚Äî
def load(image_file):
    image = tf.io.read_file(image_file)
    image = tf.image.decode_jpeg(image)
    w = tf.shape(image)[1] // 2
    return tf.cast(image[:, :w, :], tf.float32), tf.cast(image[:, w:, :], tf.float32)

def resize(inp, tar, size=256):
    inp = tf.image.resize(inp, [size, size])
    tar = tf.image.resize(tar, [size, size])
    return inp, tar

def normalize(inp, tar):
    return (inp / 127.5 - 1), (tar / 127.5 - 1)

def preprocess(image_file):
    inp, tar = load(image_file)
    inp, tar = resize(inp, tar)
    return normalize(inp, tar)

train_ds = tf.data.Dataset.list_files(PATH + '/train/*.jpg')
train_ds = train_ds.map(preprocess).shuffle(100).batch(1)

# ‚Äî Generator (simplified U-Net) ‚Äî
def downsample(filters, size, apply_batchnorm=True):
    seq = tf.keras.Sequential()
    seq.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', use_bias=False))
    if apply_batchnorm:
        seq.add(tf.keras.layers.BatchNormalization())
    seq.add(tf.keras.layers.LeakyReLU())
    return seq

def upsample(filters, size, apply_dropout=False):
    seq = tf.keras.Sequential()
    seq.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same', use_bias=False))
    seq.add(tf.keras.layers.BatchNormalization())
    if apply_dropout:
        seq.add(tf.keras.layers.Dropout(0.5))
    seq.add(tf.keras.layers.ReLU())
    return seq

def Generator():
    inp = tf.keras.layers.Input(shape=[256, 256, 3])
    downs = [downsample(f, 4, i==0) for i, f in enumerate([64,128,256,512,512,512,512,512])]
    ups = [upsample(f, 4, d) for d, f in zip([True,True,True,False,False,False,False],[512,512,512,512,256,128,64])]
    x, skips = inp, []
    for d in downs:
        x = d(x); skips.append(x)
    for u, skip in zip(ups, reversed(skips[:-1])):
        x = u(x); x = tf.keras.layers.Concatenate()([x, skip])
    out = tf.keras.layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(x)
    return tf.keras.Model(inputs=inp, outputs=out)

model = Generator()

# ‚Äî Display one example ‚Äî
for inp, tar in train_ds.take(145):
    fake = model(inp, training=False)
    plt.figure(figsize=(12,4))
    for i, img in enumerate([inp[0], tar[0], fake[0]]):
        plt.subplot(1,3,i+1)
        plt.imshow((img + 1) / 2); plt.axis('off')
        plt.title(['Input','Target','Generated'][i])
    plt.show()

# Commented out IPython magic to ensure Python compatibility.
# üõ†Ô∏è Install TensorFlow CPU & dependencies
!pip install -q tensorflow-cpu matplotlib

# üì• Clone the official Pix2Pix GitHub to access download script
!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git

# üíæ Navigate to the dataset download script for Pix2Pix
# %cd pytorch-CycleGAN-and-pix2pix
!bash ./datasets/download_pix2pix_dataset.sh maps

# üìÅ Verify the downloaded dataset
!ls datasets/maps/train/*.jpg | head -n 5

!pip install tensorflow